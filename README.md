# ColdStart-FlowCF-TF
**Flow Matching based Cold-Start Recommendation System (TensorFlow Implementation)**

This repository implements a **Continuous-Time Flow Matching** model for recommender systems, specifically designed to address the **Cold-Start Problem**.

By utilizing **User Activity Priors (Bernoulli/Gaussian distributions)** instead of pure Gaussian noise as the initial state ($x_0$), this model effectively infers the preference distribution of new items (Cold Items) using only their side information (e.g., tags, genres).

---

## ğŸ“‚ 1. Directory Structure

```text
ColdStart-FlowCF-TF/
â”œâ”€â”€ data/                     # Dataset directory
â”‚   â”œâ”€â”€ ML1M/                 # MovieLens-1M raw data
â”‚   â””â”€â”€ side_info.npy         # Pre-processed Item Side Information (Embeddings)
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py        # Data pipeline with Cold-Start masking strategy
â”‚   â”œâ”€â”€ model.py              # FlowModel architecture (MLP + Time Embeddings)
â”‚   â”œâ”€â”€ flow_logic.py         # Flow Matching logic (Vector Field & ODE Solver)
â”‚   â””â”€â”€ metrics.py            # Evaluation metrics (Recall@K, NDCG@K)
â”œâ”€â”€ config.yaml      # Hyperparameter configurations
â”œâ”€â”€ train.py                  # Main training loop with tf.GradientTape
â”œâ”€â”€ evaluate.py               # Evaluation script for cold-start scenarios
â”œâ”€â”€ run_all.py                # Automated experiment script (Step ablation study)
â”œâ”€â”€ inference.py              # Single item inference script
â”œâ”€â”€ Dockerfile                # Docker build configuration
â”œâ”€â”€ docker-compose.yml        # Container orchestration and port settings
â””â”€â”€ requirements.txt          # Python dependencies
```

## ğŸ³ 2. Environment Setup (Docker)
This project is optimized for TensorFlow GPU environments. We strongly recommend using Docker and Docker Compose for a seamless setup.

Prerequisites
Docker & Docker Compose

NVIDIA GPU Driver & NVIDIA Container Toolkit

Quick Start
Build and run the container using docker-compose. This handles port forwarding (6006) and volume mounting automatically.

```Bash
# 1. Build and start the container in background
docker compose up -d --build

# 2. Access the container shell
docker exec -it cold_flow_tf /bin/bash
```
Note: The docker-compose.yml mounts the current directory to /app. Any code changes made locally will be immediately reflected inside the container.


## ğŸš€ 3. Usage
Run the following commands inside the Docker container.

3.1. Training (Single Run)
Train the model with a specific number of Euler steps.


```Bash
# Train with default 10 steps
python train.py --steps 10
```
--steps: Defines both training time-discretization ($n\_step$) and inference sampling steps.

## ğŸ“Š 4. Monitoring (TensorBoard)
Real-time monitoring of Loss curves and Recall@20 performance.

Launch TensorBoard inside the container:
```Bash
tensorboard --logdir logs/ --port 6006 --bind_all
```
Access from your local machine:

Open your browser and visit: http://localhost:6006

VS Code Users: Go to the PORTS tab (bottom panel) and click the globe icon (ğŸŒ) next to port 6006.


